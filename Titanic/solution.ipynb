{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and Gain Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"../../datasets/titanic/train.csv\")\n",
    "\n",
    "# The target values are should be drop from rest of dataset\n",
    "X_train = train_data.drop(\"Survived\", axis=\"columns\")\n",
    "y_train = train_data[\"Survived\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Pclass       891 non-null    int64  \n",
      " 2   Name         891 non-null    object \n",
      " 3   Sex          891 non-null    object \n",
      " 4   Age          714 non-null    float64\n",
      " 5   SibSp        891 non-null    int64  \n",
      " 6   Parch        891 non-null    int64  \n",
      " 7   Ticket       891 non-null    object \n",
      " 8   Fare         891 non-null    float64\n",
      " 9   Cabin        204 non-null    object \n",
      " 10  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, whole dataset is almost complete (i.e. there are a few nan values in the dataset). But still there are some values that must be complete or drop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data to Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop([\"Cabin\", \"Ticket\", \"Name\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to almost entire __cabin__ feature is nan, it must be drop. Because it can't be filling since the filling operation will damage the dataset. The reason of dropped some other features is what they must be numeric value or scalable value. But these features are not scalable since they are almost unique. (e.g. all names in the dataset might be unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This transformer select columns according to \"columns\" paramater.\n",
    "# It is used for distinguish numeric value from categorical (non-numeric) value or vice versa.\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnSelection(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline ([\n",
    "    (\"selected_num\", ColumnSelection([\"Age\", \"SibSp\", \"Parch\", \"Fare\"])),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*num_pipeline*__ transforms numeric features in the dataset. It does this in that way:\n",
    "\n",
    "<ol>\n",
    "    <li>Select numerical features(i.e columns).</li>\n",
    "    <dd>-> ColumnSelection</dd>\n",
    "    <li>Fill empty values.</li>\n",
    "    <dd>-> SimpleImputer (fill empty values with median of non-empty values of columns)</dd>\n",
    "    <li>Scale numerical features.</li>\n",
    "    <dd>-> StandardScaller</dd>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.56573646,  0.43279337, -0.47367361, -0.50244517],\n",
       "       [ 0.66386103,  0.43279337, -0.47367361,  0.78684529],\n",
       "       [-0.25833709, -0.4745452 , -0.47367361, -0.48885426],\n",
       "       ...,\n",
       "       [-0.1046374 ,  0.43279337,  2.00893337, -0.17626324],\n",
       "       [-0.25833709, -0.4745452 , -0.47367361, -0.04438104],\n",
       "       [ 0.20276197, -0.4745452 , -0.47367361, -0.49237783]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This transformer finds the most high frequency value and fills empty values in dataset with this value.\n",
    "\n",
    "class MaxFrequency(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.frequency_ = pd.Series([X[column].value_counts().keys()[0] for column in X], index=X.columns)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.fillna(self.frequency_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    (\"selected_cat\", ColumnSelection([\"Pclass\", \"Sex\", \"Embarked\"])),\n",
    "    (\"imputer\", MaxFrequency()),\n",
    "    (\"encoder\", OneHotEncoder(sparse=False)),\n",
    "    (\"std_scaler_cat\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__cat_pipeline__ transforms categorical(i.e. non-numerical) features in the dataset. It does this in that way:\n",
    "\n",
    "<ol>\n",
    "    <li>Select categorical features</li>\n",
    "    <dd>-> ColumnSelection</dd>\n",
    "    <li>Fill empty values</li>\n",
    "    <dd>-> MaxFrequency</dd>\n",
    "    <li>Categorize values in the columns</li>\n",
    "    <dd>-> OneHotEncoder</dd>\n",
    "    <li>Scale categorical features</li>\n",
    "    <dd>-> StandardScaler</dd>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.56568542, -0.51015154,  0.90258736, ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843],\n",
       "       [ 1.76776695, -0.51015154, -1.10792599, ...,  2.0745051 ,\n",
       "        -0.30756234, -1.62380254],\n",
       "       [-0.56568542, -0.51015154,  0.90258736, ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843],\n",
       "       ...,\n",
       "       [-0.56568542, -0.51015154,  0.90258736, ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843],\n",
       "       [ 1.76776695, -0.51015154, -1.10792599, ...,  2.0745051 ,\n",
       "        -0.30756234, -1.62380254],\n",
       "       [-0.56568542, -0.51015154,  0.90258736, ..., -0.48204268,\n",
       "         3.25137334, -1.62380254]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pipeline consist from other two pipeline which defined earlier.\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num\", num_pipeline),\n",
    "    (\"cat\", cat_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = full_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting and Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier is selected as classifier with \"42\" random state\n",
    "# You can select a number whatever you want as random state\n",
    "# This makes sure that RandomForestClassifier will generated as same every time\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest_clf.predict(X_train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732142857142858"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797979797979798"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for the best models parameters \n",
    "\n",
    "param_grid = [\n",
    "    {\"n_estimators\":[50, 100, 200], \"bootstrap\": [True, False], \"ccp_alpha\":[0.5, 1.0]}\n",
    "]\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(forest_clf, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid=[{'bootstrap': [True, False], 'ccp_alpha': [0.5, 1.0],\n",
       "                          'n_estimators': [50, 100, 200]}])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True, 'ccp_alpha': 0.5, 'n_estimators': 50}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and generating a model from scratch with best parameters\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42, bootstrap=True, ccp_alpha=0.5, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv_pred = cross_val_predict(forest_clf, X_train_prepared, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It seems like model has not done any mistake\n",
    "\n",
    "f1_score(y_train, y_cv_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161616161616161"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but indeed there is an overfitting\n",
    "\n",
    "accuracy_score(y_train, y_cv_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, another model is selected to compare other model\n",
    "\n",
    "log_clf = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for best models parameters\n",
    "\n",
    "param_grid_log = [\n",
    "    {\"C\": [1, 2, 3, 4, 5], \"max_iter\":[100, 500, 1000, 3000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_log = GridSearchCV(log_clf, param_grid_log, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
       "             param_grid=[{'C': [1, 2, 3, 4, 5],\n",
       "                          'max_iter': [100, 500, 1000, 3000]}])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_log.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'max_iter': 100}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_log.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, instead of generate a model with best parameters from scratch, \n",
    "# GridSearchCV best_estimator_ attribute is used.\n",
    "# It returns the model which was found best parameters for it.\n",
    "\n",
    "log_estimator = grid_search_log.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pred = cross_val_predict(log_estimator, X_train_prepared, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7192716236722307"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These scores are lower than the previous one. \n",
    "# Thereby, for this solution, RandomForestClassifier was used.\n",
    "\n",
    "f1_score(y_train, log_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792368125701459"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, log_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import test data\n",
    "\n",
    "test_set = pd.read_csv(\"../../datasets/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data\n",
    "\n",
    "test_set_prepared = full_pipeline.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "\n",
    "y_test_pred = forest_clf.predict(test_set_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating submission file\n",
    "\n",
    "submission = pd.DataFrame(y_test_pred, index=test_set[\"PassengerId\"], columns=[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and writing to the submission file.\n",
    "\n",
    "submission.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
